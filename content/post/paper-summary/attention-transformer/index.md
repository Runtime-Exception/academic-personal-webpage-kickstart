---
title: "Paper Summary : Attention is all you need."
summary: 'Summary about the paper on Transformer Networks by Pierre-Ashish Vaswani et. al. from Google'
date: 2021-04-23T11:37:38-05:00
lastmod: "`r format(Sys.time(), '%d %B %Y')`"
authors:
- admin
tags:
- Paper Reading
draft: false
math: true

---

### Summary
This [paper](https://arxiv.org/pdf/1706.03762.pdf) presented the Transformer Network based on Self attention which is used build up NLP models like BERT or GPT.

**Transformer Model architecture:**


{{< figure src="model.png" align="center" >}}

**My thoughts:**
